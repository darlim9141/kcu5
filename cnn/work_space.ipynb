{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8612efd1",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 및 전처리\n",
    "\n",
    "-   **데이터셋 구성**\n",
    "    -   웹 스크레이핑을 통해 수집한 자체 데이터셋을 사용할 예정.\n",
    "    -   클래스는 **Street, Minimal, Amekaji, Feminine** 총 4개.\n",
    "    -   데이터는 클래스당 100장의 Full body 이미지, 총 400장으로 구성됨.\n",
    "\n",
    "-   **전처리 및 데이터 증강 계획**\n",
    "    -   모든 이미지는 사전 훈련 모델의 입력 크기인 `(224, 224)`로 표준화할 것.\n",
    "    -   픽셀 값은 `[0, 1]` 범위로 정규화하여 학습 안정성을 확보할 예정.\n",
    "    -   훈련 데이터에 한해 `ImageDataGenerator`를 활용, Data Augmentation을 적용하여 모델의 과적합을 방지하고 일반화 성능을 향상."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "DATA_DIR = '../image'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                 \n",
    "    rotation_range=20,             \n",
    "    width_shift_range=0.2,          \n",
    "    height_shift_range=0.2,        \n",
    "    shear_range=0.2,                \n",
    "    zoom_range=0.2,                 \n",
    "    horizontal_flip=True,           \n",
    "    fill_mode='nearest',            \n",
    "    validation_split=0.2            \n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ae7cf",
   "metadata": {},
   "source": [
    "### 2. 모델 아키텍처 및 훈련\n",
    "\n",
    "-   **모델 아키텍처 선정**\n",
    "    -   전이 학습의 효과와 아키텍처별 성능 비교를 위해 **VGG16**과 **ResNet50**을 각각 베이스라인 및 비교 모델로 사용.\n",
    "    -   두 모델 모두 ImageNet으로 사전 훈련된 **합성곱 베이스(Convolutional Base)의 가중치는 동결(Freeze)**하여 사용될 예정.\n",
    "\n",
    "-   **미세조정(Fine-tuning) 설계**\n",
    "    -   동결된 베이스 모델 위에 Classifier Head를 추가할 계획.\n",
    "    -   분류기는 `GlobalAveragePooling2D`, `Dropout(0.5)`, `Dense(1024, 'relu')`, 그리고 최종 `Dense(4, 'softmax')` 층으로 구성됨. `Dropout`을 통해 과적합을 억제할 예정.\n",
    "\n",
    "-   **훈련 계획**\n",
    "    -   옵티마이저는 `Adam`, 손실 함수는 `categorical_crossentropy`를 사용할 것.\n",
    "    -   훈련은 초기 20 에포크(Epoch) 동안 진행하며, 학습 곡선(정확도 및 손실)을 시각화하여 과적합 여부를 검토할 예정.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c624a",
   "metadata": {},
   "source": [
    "### 3. 모델 성능 평가\n",
    "\n",
    "- **정량적 평가**\n",
    "    - 검증 데이터셋을 통해 훈련된 각 모델의 최종 성능을 정량적으로 평가.\n",
    "    - **평가 지표:** Accuracy, Precision, Recall, F1-Score를 핵심 지표로 사용.\n",
    "\n",
    "- **결과 제시**\n",
    "    - VGG16과 ResNet50 모델의 최종 성능을 비교 제시하여 아키텍처별 효율성을 분석.\n",
    "    - Confusion Matrix을 시각화하여, 모델이 어떤 클래스 간에 혼동을 보이는지 분석."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e01ee2",
   "metadata": {},
   "source": [
    "### 4. 모델 해석 및 정성적 분석\n",
    "\n",
    "- **정성적 분석**\n",
    "    - 모델의 의사결정 과정을 시각적으로 해석하기 위해 정성적 분석을 수행.\n",
    "    - **분석 기법:** Grad-CAM을 사용하여 예측의 근거가 되는 이미지 내 Attention을 시각화.\n",
    "\n",
    "- **결과 제시**\n",
    "    - 각 스타일별 예측에 대한 Grad-CAM 히트맵 예시를 제시.\n",
    "\n",
    "- **분석 목표**\n",
    "    - 시각화 결과를 통해 모델이 단순히 데이터의 패턴을 암기한 것이 아니라, 각 스타일을 정의하는 유의미한 Semantic 특징을 학습했는지 확인할 계획."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
