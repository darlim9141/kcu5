{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8612efd1",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 및 전처리\n",
    "\n",
    "-   **데이터셋 구성**\n",
    "    -   웹 스크레이핑을 통해 수집한 자체 데이터셋을 사용할 예정.\n",
    "    -   클래스는 **Street, Minimal, Amekaji, Feminine** 총 4개.\n",
    "    -   데이터는 클래스당 100장의 Full body 이미지, 총 400장으로 구성됨.\n",
    "\n",
    "-   **전처리 및 데이터 증강 계획**\n",
    "    -   모든 이미지는 사전 훈련 모델의 입력 크기인 `(224, 224)`로 표준화할 것.\n",
    "    -   픽셀 값은 `[0, 1]` 범위로 정규화하여 학습 안정성을 확보할 예정.\n",
    "    -   훈련 데이터에 한해 `ImageDataGenerator`를 활용, Data Augmentation을 적용하여 모델의 과적합을 방지하고 일반화 성능을 향상."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c40eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "DATA_DIR = '../image'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,                 \n",
    "    rotation_range=20,             \n",
    "    width_shift_range=0.2,          \n",
    "    height_shift_range=0.2,        \n",
    "    shear_range=0.2,                \n",
    "    zoom_range=0.2,                 \n",
    "    horizontal_flip=True,           \n",
    "    fill_mode='nearest',            \n",
    "    validation_split=0.2            \n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccecb061-e790-48cc-ad65-4897ccb387be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 1. 데이터셋 및 전처리 (간단 버전) ===\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "DATA_DIR = '../image'\n",
    "IMAGE_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "VAL_SPLIT = 0.2\n",
    "\n",
    "# 폴더명과 동일한 클래스 순서 고정\n",
    "CLASS_NAMES = ['Street', 'Minimal', 'Amekaji', 'Feminine']\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=VAL_SPLIT\n",
    ")\n",
    "\n",
    "train_gen = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=CLASS_NAMES,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "valid_gen = valid_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    classes=CLASS_NAMES,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "steps_per_epoch   = max(1, train_gen.samples // BATCH_SIZE)\n",
    "validation_steps  = max(1, valid_gen.samples // BATCH_SIZE)\n",
    "print(\"클래스 인덱스:\", train_gen.class_indices)\n",
    "print(\"학습/검증 샘플 수:\", train_gen.samples, valid_gen.samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071ae7cf",
   "metadata": {},
   "source": [
    "### 2. 모델 아키텍처 및 훈련\n",
    "\n",
    "-   **모델 아키텍처 선정**\n",
    "    -   전이 학습의 효과와 아키텍처별 성능 비교를 위해 **VGG16**과 **ResNet50**을 각각 베이스라인 및 비교 모델로 사용.\n",
    "    -   두 모델 모두 ImageNet으로 사전 훈련된 **합성곱 베이스(Convolutional Base)의 가중치는 동결(Freeze)**하여 사용될 예정.\n",
    "\n",
    "-   **미세조정(Fine-tuning) 설계**\n",
    "    -   동결된 베이스 모델 위에 Classifier Head를 추가할 계획.\n",
    "    -   분류기는 `GlobalAveragePooling2D`, `Dropout(0.5)`, `Dense(1024, 'relu')`, 그리고 최종 `Dense(4, 'softmax')` 층으로 구성됨. `Dropout`을 통해 과적합을 억제할 예정.\n",
    "\n",
    "-   **훈련 계획**\n",
    "    -   옵티마이저는 `Adam`, 손실 함수는 `categorical_crossentropy`를 사용할 것.\n",
    "    -   훈련은 초기 20 에포크(Epoch) 동안 진행하며, 학습 곡선(정확도 및 손실)을 시각화하여 과적합 여부를 검토할 예정.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851f0a16-7449-42fd-93c4-3f03cd3ddba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 2. 모델 아키텍처 & 훈련 (간단 버전) ===\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import VGG16, ResNet50\n",
    "\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "\n",
    "def build_model(arch='vgg16', input_shape=(224,224,3), num_classes=4, freeze_base=True):\n",
    "    if arch == 'vgg16':\n",
    "        base = VGG16(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    elif arch == 'resnet50':\n",
    "        base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    else:\n",
    "        raise ValueError(\"arch는 'vgg16' 또는 'resnet50'만 허용\")\n",
    "\n",
    "    base.trainable = not freeze_base  # 간단: 기본은 동결(True)\n",
    "    x = layers.Input(shape=input_shape)\n",
    "    y = base(x, training=False)\n",
    "    y = layers.GlobalAveragePooling2D()(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "    y = layers.Dense(1024, activation='relu')(y)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(y)\n",
    "    model = models.Model(x, out)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def train_once(arch, epochs=10):\n",
    "    print(f\"\\n=== Training: {arch.upper()} ===\")\n",
    "    model = build_model(arch=arch, input_shape=(*IMAGE_SIZE,3), num_classes=NUM_CLASSES, freeze_base=True)\n",
    "    es = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
    "    hist = model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=steps_per_epoch,\n",
    "        validation_data=valid_gen,\n",
    "        validation_steps=validation_steps,\n",
    "        epochs=epochs,\n",
    "        callbacks=[es],\n",
    "        verbose=1\n",
    "    )\n",
    "    # 간단 평가\n",
    "    val_loss, val_acc = model.evaluate(valid_gen, steps=validation_steps, verbose=0)\n",
    "    print(f\"[{arch.upper()}] Val Acc = {val_acc:.4f}\")\n",
    "\n",
    "    # 학습곡선 간단 플롯(정확도만)\n",
    "    plt.figure(figsize=(5,3))\n",
    "    plt.plot(hist.history['accuracy'], label='train')\n",
    "    plt.plot(hist.history['val_accuracy'], label='val')\n",
    "    plt.title(f'{arch.upper()} Accuracy')\n",
    "    plt.xlabel('epoch'); plt.ylabel('acc'); plt.legend(); plt.show()\n",
    "    return model, hist\n",
    "\n",
    "# VGG16 먼저 간단 학습\n",
    "vgg_model, vgg_hist = train_once('vgg16', epochs=10)\n",
    "\n",
    "# 이어서 ResNet50 간단 학습\n",
    "res_model, res_hist = train_once('resnet50', epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c624a",
   "metadata": {},
   "source": [
    "### 3. 모델 성능 평가\n",
    "\n",
    "- **정량적 평가**\n",
    "    - 검증 데이터셋을 통해 훈련된 각 모델의 최종 성능을 정량적으로 평가.\n",
    "    - **평가 지표:** Accuracy, Precision, Recall, F1-Score를 핵심 지표로 사용.\n",
    "\n",
    "- **결과 제시**\n",
    "    - VGG16과 ResNet50 모델의 최종 성능을 비교 제시하여 아키텍처별 효율성을 분석.\n",
    "    - Confusion Matrix을 시각화하여, 모델이 어떤 클래스 간에 혼동을 보이는지 분석."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e01ee2",
   "metadata": {},
   "source": [
    "### 4. 모델 해석 및 정성적 분석\n",
    "\n",
    "- **정성적 분석**\n",
    "    - 모델의 의사결정 과정을 시각적으로 해석하기 위해 정성적 분석을 수행.\n",
    "    - **분석 기법:** Grad-CAM을 사용하여 예측의 근거가 되는 이미지 내 Attention을 시각화.\n",
    "\n",
    "- **결과 제시**\n",
    "    - 각 스타일별 예측에 대한 Grad-CAM 히트맵 예시를 제시.\n",
    "\n",
    "- **분석 목표**\n",
    "    - 시각화 결과를 통해 모델이 단순히 데이터의 패턴을 암기한 것이 아니라, 각 스타일을 정의하는 유의미한 Semantic 특징을 학습했는지 확인할 계획."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kcu5-tf",
   "language": "python",
   "name": "kcu5-tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
